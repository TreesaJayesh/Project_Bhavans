# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19UYoMeBEiY146Pywr9enU67foYnkWzx-
"""

s=10-3
print(s)

from ultralytics import YOLO
import cv2
from google.colab import files
import matplotlib.pyplot as plt
# Load the pre-trained YOLO model
model = YOLO("yolov8n.pt")  # You can use other versions like yolov8s, yolov8m, etc.

# Upload the bus photo
uploaded = files.upload()
image_path = list(uploaded.keys())[0]

image = cv2.imread('th.jpg')
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for display

# YOLO model on the image
results = model(image)
# Count the number of passengers and vacant seats
passenger_count = 0
seat_count = 0

for result in results:
    for box in result.boxes:
        class_id = int(box.cls)
        if class_id == 0:  # Class ID 0 corresponds to 'person' in YOLO
            passenger_count += 1
        elif class_id == 62:  # Class ID 62 corresponds to 'chair' in YOLO (assuming seats are chairs)
            seat_count += 1


print(f"Number of passengers: {passenger_count}")
print(f"Number of vacant seats: {seat_count - passenger_count}")


result_image = results[0].plot()
plt.imshow(result_image)
plt.axis('off')
plt.show()

from ultralytics import YOLO

pip install ultralytics

pip install opencv-python

import cv2

pip install google-colab

from google.colab import files

pip install matplotlib

import matplotlib.pyplot as plt

model = YOLO("yolov8n.pt")

pip install ultralytics

model = YOLO("yolov8n.pt")

from ultralytics import YOLO

model = YOLO("yolov8n.pt")

uploaded = files.upload()



image_path = list(uploaded.keys())[0]



image = cv2.imread('GOO.jpg')

image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

results = model(image)

passenger_count = 0

seat_count = 0

for result in results:
    for box in result.boxes:
        class_id = int(box.cls)
        if class_id == 0:  # Class ID 0 corresponds to 'person' in YOLO
            passenger_count += 1
        elif class_id == 62:  # Class ID 62 corresponds to 'chair' in YOLO (assuming seats are chairs)
            seat_count += 1

print(f"Number of passengers: {passenger_count}")
print(f"Number of vacant seats: {seat_count - passenger_count}")

result_image = results[0].plot()
plt.imshow(result_image)
plt.axis('off')
plt.show()



import cv2
import numpy as np

net = cv2.dnn.readNet("yolo_files/yolov4.weights", "yolo_files/yolov4.cfg")

yolo_files/
    yolov4.cfg
    yolov4.weights
    coco.names

from ultralytics import YOLO

from ultralytics import YOLO

pip install ultralytics

from ultralytics import YOLO

net = cv2.dnn.readNet("yolo_files/yolov4.weights", "yolo_files/yolov4.cfg")

pip install opencv-python

net = cv2.dnn.readNet("yolo_files/yolov4.weights", "yolo_files/yolov4.cfg")

net = cv2.dnn.readNet("yolo_files/yolov4.weights", "yolo_files/yolov4.cfg")

net = cv2.dnn.readNetFromDarknet("/absolute/path/to/yolo_files/yolov4.cfg", "/absolute/path/to/yolo_files/yolov4.weights")

import os
cfg_path = 'yolo_files/yolov4.cfg'
weights_path = 'yolo_files/yolov4.weights'

print("CFG file exists:", os.path.exists(cfg_path))
print("Weights file exists:", os.path.exists(weights_path))

if not os.path.exists(cfg_path) or not os.path.exists(weights_path):
    print("Check the paths and ensure the files are in the correct location!")

mkdir -p yolo_files

wget https://github.com/AlexeyAB/darknet/raw/master/cfg/yolov4.cfg -O yolo_files/yolov4.cfg
wget https://pjreddie.com/media/files/yolov4.weights -O yolo_files/yolov4.weights

import os

cfg_path = 'yolo_files/yolov4.cfg'

weights_path = 'yolo_files/yolov4.weights'

print("Checking files...")
print("CFG file exists:", os.path.exists(cfg_path))
print("Weights file exists:", os.path.exists(weights_path))

if not os.path.exists(cfg_path):
    print(f"{cfg_path} not found!")
if not os.path.exists(weights_path):
    print(f"{weights_path} not found!")

mkdir -p yolo_files
mv yolov4.cfg yolov4.weights yolo_files/

pip install opencv-python-headless
pip install opencv-python

!pip install opencv-python-headless
!pip install opencv-python

# Commented out IPython magic to ensure Python compatibility.
# Clone Darknet repository
!git clone https://github.com/AlexeyAB/darknet

# Change directory to Darknet
# %cd darknet

# Download YOLOv4 weights and cfg files
!wget https://github.com/AlexeyAB/darknet/raw/master/cfg/yolov4.cfg
!wget https://pjreddie.com/media/files/yolov4.weights

# Compile Darknet (you only need to run this once)
!make

pip install time

import time

import cv2

import numpy as np
from matplotlib import pyplot as plt
from IPython.display import display, Javascript, clear_output
from google.colab.output import eval_js
from base64 import b64decode

pip install opencv-python-headless opencv-contrib-python

"""def take_photo(filename='photo.jpg', quality=0.8):
    js = Javascript('''
        async function takePhoto(quality) {
            const div = document.createElement('div');
            const video = document.createElement('video');
            video.style.display = 'block';
            const stream = await navigator.mediaDevices.getUserMedia({video: true});
            document.body.appendChild(div);
            div.appendChild(video);
            video.srcObject = stream;
            await video.play();
            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);
            await new Promise(resolve => setTimeout(resolve, 100)); // Added delay
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            stream.getVideoTracks()[0].stop();
            div.remove();
            return canvas.toDataURL('image/jpeg', quality);
        }
    ''')
    display(js)
    data = eval_js('takePhoto({})'.format(quality))
    binary = b64decode(data.split(',')[1])
    with open(filename, 'wb') as f:
        f.write(binary)
    return filename

def detect_faces(image_path):
    image = cv2.imread(image_path)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    for (x, y, w, h) in faces:
        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)
    return image, len(faces)

try:
    i = 0
    while True:
        clear_output(wait=True)
        print(f"Taking photo {i+1}...")
        filename = take_photo(f'photo_{i}.jpg')
        image_with_faces, num_faces = detect_faces(filename)
        plt.imshow(cv2.cvtColor(image_with_faces, cv2.COLOR_BGR2RGB))
        plt.axis('off')
        plt.title(f"Number of people detected: {num_faces}")
        plt.show()
        i += 1
        time.sleep(10)

except KeyboardInterrupt:
    print("Stopped taking photos.")
"""

def take_photo(filename='photo.jpg', quality=0.8):
    js = Javascript('''
        async function takePhoto(quality) {
            const div = document.createElement('div');
            const video = document.createElement('video');
            video.style.display = 'block';
            const stream = await navigator.mediaDevices.getUserMedia({video: true});
            document.body.appendChild(div);
            div.appendChild(video);
            video.srcObject = stream;
            await video.play();
            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);
            await new Promise(resolve => setTimeout(resolve, 100)); // Added delay
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            stream.getVideoTracks()[0].stop();
            div.remove();
            return canvas.toDataURL('image/jpeg', quality);
        }
    ''')
    display(js)
    data = eval_js('takePhoto({})'.format(quality))
    binary = b64decode(data.split(',')[1])
    with open(filename, 'wb') as f:
        f.write(binary)
    return filename

def detect_faces(image_path):
    image = cv2.imread(image_path)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    for (x, y, w, h) in faces:
        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)
    return image, len(faces)

try:
    i = 0
    while True:
        clear_output(wait=True)
        print(f"Taking photo {i+1}...")
        filename = take_photo(f'photo_{i}.jpg')
        image_with_faces, num_faces = detect_faces(filename)
        plt.imshow(cv2.cvtColor(image_with_faces, cv2.COLOR_BGR2RGB))
        plt.axis('off')
        plt.title(f"Number of people detected: {num_faces}")
        plt.show()
        i += 1
        time.sleep(10)

except KeyboardInterrupt:
    print("Stopped taking photos.")

pip install flask

import random

from flask import Flask, jsonify

app = Flask(__name__)

@app.route('/get_data')

def get_data():
    # Return some random data
    return jsonify({'data': random.randint(1, 100)})

if __name__ == '__main__':
    app.run(port=5000)

pip install flask-ngrok

from flask_ngrok import run_with_ngrok
run_with_ngrok(app)

pip install flask-ngrok

from flask_ngrok import run_with_ngrok
run_with_ngrok(app)

!pip install flask-ngrok
from flask import Flask, jsonify
from flask_ngrok import run_with_ngrok

app = Flask(__name__)

@app.route('/')
def hello():
    return "Hello, World!"

@app.route('/get_data')
def get_data():
    return jsonify({"data": "This is some data"})

run_with_ngrok(app)

if __name__ == "__main__":
    app.run()

